---
title: 秒杀项目
date: 2019-03-04 00:09:37
author: fuf
notebook: blog
evernote-version: 0
source: 原创/转载
thumbnail: 
tags:
    - 默认
blogexcerpt:
---



## 架构图

## 数据表设计


## 项目解决问题
1. 如何解决卖超问题
- 在sql加上判断防止数据边为负数 
- 数据库加唯一索引防止用户重复购买
- redis预减库存减少数据库访问　内存标记减少redis访问　请求先入队列缓冲，异步下单，增强用户体验


<!-- more -->

1. 页面级缓存thymeleafViewResolver
2. 订单处理队列rabbitmq
3. 解决分布式session
4. 秒杀安全 -- 安全性设计
- 秒杀接口隐藏
- 数字公式验证码
- 接口防刷限流(通用 注解，拦截器方式)

6. 通用缓存key的封装采用什么设计模式
7. redis的库存如何与数据库的库存保持一致
redis的数量不是库存,他的作用仅仅只是为了阻挡多余的请求透穿到DB，起到一个保护的作用
因为秒杀的商品有限，比如10个，让1万个请求区访问DB是没有意义的，因为最多也就只能10个
请求下单成功，所有这个是一个伪命题，我们是不需要保持一致的

8.  为什么redis数量会减少为负数

    //预见库存
    long stock = redisService.decr(GoodsKey.getMiaoshaGoodsStock,""+goodsId) ;
	if(stock <0){
    localOverMap.put(goodsId, true);
	return Result.error(CodeMsg.MIAO_SHA_OVER);
	}
	假如redis的数量为1,这个时候同时过来100个请求，大家一起执行decr数量就会减少成-99这个是正常的
	进行优化后改变了sql写法和内存写法则不会出现上述问题
9.  为什么要单独维护一个秒杀结束标志

- 1.前提所有的秒杀相关的接口都要加上活动是否结束的标志，如果结束就直接返回，包括轮寻的接口防止一直轮寻
- 2.管理后台也可以手动的更改这个标志，防止出现活动开始以后就没办法结束这种意外的事件
10. rabbitmq如何做到消息不重复不丢失即使服务器重启
11. 为什么threadlocal存储user对象，原理

1.并发编程中重要的问题就是数据共享，当你在一个线程中改变任意属性时，所有的线程都会因此受到影响，同时会看到第一个线程修改后的值<br>
有时我们希望如此，比如：多个线程增大或减小同一个计数器变量<br>
但是，有时我们希望确保每个线程，只能工作在它自己 的线程实例的拷贝上，同时不会影响其他线程的数据<br>

举例： 举个例子，想象你在开发一个电子商务应用，你需要为每一个控制器处理的顾客请求，生成一个唯一的事务ID，同时将其传到管理器或DAO的业务方法中，
以便记录日志。一种方案是将事务ID作为一个参数，传到所有的业务方法中。但这并不是一个好的方案，它会使代码变得冗余。   
你可以使用ThreadLocal类型的变量解决这个问题。首先在控制器或者任意一个预处理器拦截器中生成一个事务ID
然后在ThreadLocal中 设置事务ID，最后，不论这个控制器调用什么方法，都能从threadlocal中获取事务ID
而且这个应用的控制器可以同时处理多个请求，
同时在框架 层面，因为每一个请求都是在一个单独的线程中处理的，所以事务ID对于每一个线程都是唯一的，而且可以从所有线程的执行路径获取
运行结果可以看出每个线程都在维护自己的变量：
 Starting Thread: 0 : Fri Sep 21 23:05:34 CST 2018<br>
 Starting Thread: 2 : Fri Sep 21 23:05:34 CST 2018<br>
 Starting Thread: 1 : Fri Jan 02 05:36:17 CST 1970<br>
 Thread Finished: 1 : Fri Jan 02 05:36:17 CST 1970<br>
 Thread Finished: 0 : Fri Sep 21 23:05:34 CST 2018<br>
 Thread Finished: 2 : Fri Sep 21 23:05:34 CST 2018<br>
 
 局部线程通常使用在这样的情况下，当你有一些对象并不满足线程安全，但是你想避免在使用synchronized关键字<br>
 块时产生的同步访问，那么，让每个线程拥有它自己的对象实例<br>
 注意：局部变量是同步或局部线程的一个好的替代，它总是能够保证线程安全。唯一可能限制你这样做的是你的应用设计约束<br>
 所以设计threadlocal存储user不会对对象产生影响，每次进来一个请求都会产生自身的线程变量来存储
12. maven 隔离
13. redis 分布式锁实现方法

我用了四种方法 ， 分别指出了不同版本的缺陷以及演进的过程 orderclosetask
V1---->>版本没有操作，在分布式系统中会造成同一时间，资源浪费而且很容易出现并发问题  
V2--->>版本加了分布式redis锁，在访问核心方法前，加入redis锁可以阻塞其他线程访问,可以  
很好的处理并发问题,但是缺陷就是如果机器突然宕机，或者线路波动等，就会造成死锁，一直
不释放等问题
V3版本-->>很好的解决了这个问题v2的问题，就是加入时间对比如果当前时间已经大与释放锁的时间
说明已经可以释放这个锁重新在获取锁，setget方法可以把之前的锁去掉在重新获取,旧值在于之前的
值比较，如果无变化说明这个期间没有人获取或者操作这个redis锁，则可以重新获取  
V4---->>采用成熟的框架redisson,封装好的方法则可以直接处理，但是waittime记住要这只为0  
14. 定时关单模拟与分布式锁
15. tomcat配置和优化
16. tomcat集群配置
17. Nginx优化（前端缓存）

1. 并发优化
2. KeepALive长连接优化
3. 压缩优化
4. 配置缓存
18. 分布式事物解决方案
19. mysql主从复制思路及实操
20. 如何进行分库分表	
21. 秒杀类似场景sql的写？
22. 如何利用lua脚本进行操作限流与分布式锁（可保证原子性）？

1.redis分布式锁,zk分布式锁,lua脚本限流,lua分布式锁
2.redis持久化策略
3.redis集群
4.redis的简单操练
1 redis分布式锁
1.分布式系统（单机的使用ReentrantLock或者synchronized代码块来实现） 2.共享资源大并发产生 3.同步访问

redis分布式锁解决什么问题

1.一个进程中的多个线程,多个线程并发访问同一个资源的时候,如何解决线程安全问题。
2.一个分布式架构系统中的两个模块同时去访问一个文件对文件进行读写操作
3.多个应用对同一条数据做修改的时候,如何保证数据的安全性
在但一个进程中,我们可以用到synchronized、lock之类的同步操作去解决,但是对于分布式架构下多进程的情况下,
如何做到跨进程的锁。就需要借助一些第三方手段来完成


23. 如何利用lua脚本进行分布式锁操作？
24. 网站访问统计实现？
25. 如何利用lua + redis 取代 nigix + lua 脚本进行分布式限流
26. 多数据源配置 如何进行多数据源配置
![](https://ws1.sinaimg.cn/large/007SLs93ly1g656oej0srj30y70emwf5.jpg)


### 数据库设计
![](https://ws1.sinaimg.cn/large/007SLs93ly1g656ouox4hj30px09h0sv.jpg)



## 分布式锁的实现。

在分布式环境下，数据一致性问题一直是一个比较重要的话题，而synchronized和lock锁在分布式环境已经失去了作用。常见的锁的方案有基于数据库实现分布式锁、基于缓存实现分布式锁、基于Zookeeper实现分布式锁，简单介绍了每种锁的实现特点。
常见的锁方案如下:
1. 基于数据库实现分布式锁。
2. 基于缓存，实现分布式锁，如redis。
3. 基于Zookeeper实现分布式锁。

### 基于数据库

1. 基于数据库表。

首先创建一张表主要包含下列字符安：方法名，时间戳等字段。  
当需要锁住某个方法时，往该表中插入一条相关的几率。方法名是有唯一性约束的如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。

执行完毕，需要delete该记录。  
应用主从数据库，数据之间双向同步。一旦挂掉快速切换到备库上；做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍；使用while循环，直到insert成功再返回成功，虽然并不推荐这样做；还可以记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了，实现可重入锁。


2. 基于数据库排他锁。
基于MySql的InnoDB引擎
```
public void lock(){
    connection.setAutoCommit(false)
    int count = 0;
    while(count < 4){
        try{
            select * from lock where lock_name=xxx for update;
            if(结果不为空){
                //代表获取到锁
                return;
            }
        }catch(Exception e){
        }
        //为空或者抛异常的话都表示没有获取到锁
        sleep(1000);
        count++;
    }
    throw new LockException();
}
```
在查询语句后面增加for update，数据库会在查询过程中给数据库表增加排他锁。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。其他没有获取到锁的就会阻塞在上述select语句上，可能的结果有2种，在超时之前获取到了锁，在超时之前仍未获取到锁。

获得排它锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，释放锁connection.commit()。

存在的问题主要是性能不高和sql超时的异常。

上述上种方法都是基于数据库一张表实现的，一种是通过表中的记录的存在情况确定当前是否有锁存在，另外一种是通过数据库的排他锁来实现分布式锁。
 - 优点是直接借助数据库，简单容易理解。
 - 缺点是操作数据库需要一定的开销，性能问题需要考虑。

### 基于Zookeeper

基于zookeeper临时有序节点可以实现的分布式锁。每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。  

提供的第三方库有curator，具体使用读者可以自行去看一下。Curator提供的InterProcessMutex是分布式锁的实现。acquire方法获取锁，release方法释放锁。另外，锁释放、阻塞锁、可重入锁等问题都可以有有效解决。讲下阻塞锁的实现，客户端可以通过在ZK中创建顺序节点，并且在节点上绑定监听器，一旦节点有变化，Zookeeper会通知客户端，客户端可以检查自己创建的节点是不是当前所有节点中序号最小的，如果是就获取到锁，便可以执行业务逻辑。  
Zookeeper实现的分布式锁其实存在一个缺点，那就是性能上可能并没有缓存服务那么高。因为每次在创建锁和释放锁的过程中，都要动态创建、销毁瞬时节点来实现锁功能。ZK中创建和删除节点只能通过Leader服务器来执行，然后将数据同不到所有的Follower机器上。并发问题，可能存在网络抖动，客户端和ZK集群的session连接断了，zk集群以为客户端挂了，就会删除临时节点，这时候其他客户端就可以获取到分布式锁了。

###  基于缓存

相对于基于数据库实现分布式锁的方案来说，基于缓存来实现在性能方面会表现的更好一点，存取速度快很多。而且很多缓存是可以集群部署的，可以解决单点问题。

#### Redis的分布式锁实现

**SETNX**  

` SETNX lock.id <current Unix time + lock timeout + 1>`
SETNX是将 key 的值设为 value，当且仅当 key 不存在。若给定的 key 已经存在，则 SETNX 不做任何动作。
- 返回1，说明该进程获得锁，SETNX将键 lock.id 的值设置为锁的超时时间，当前时间 +加上锁的有效时间。
- 返回0，说明其他进程已经获得了锁，进程不能进入临界区。进程可以在一个循环中不断地尝试 SETNX 操作，以获得锁。
**存在死锁的问题**
SETNX实现分布式锁，可能会存在死锁的情况。与单机模式下的锁相比，分布式环境下不仅需要保证进程可见，还需要考虑进程与锁之间的网络问题。某个线程获取了锁之后，断开了与Redis 的连接，锁没有及时释放，竞争该锁的其他线程都会hung，产生死锁的情况。

在使用 SETNX 获得锁时，我们将键 lock.id 的值设置为锁的有效时间，线程获得锁后，其他线程还会不断的检测锁是否已超时，如果超时，等待的线程也将有机会获得锁。然而，锁超时，我们不能简单地使用 DEL 命令删除键 lock.id 以释放锁。

考虑以下情况:

1. A已经首先获得了锁 lock.id，然后线A断线。B,C都在等待竞争该锁；
2. B,C读取lock.id的值，比较当前时间和键 lock.id 的值来判断是否超时，发现超时；
3. B执行 DEL lock.id命令，并执行 SETNX lock.id 命令，并返回1，B获得锁；
4. C由于各刚刚检测到锁已超时，执行 DEL lock.id命令，将B刚刚设置的键 lock.id 删除，执行 SETNX lock.id命令，并返回1，即C获得锁。
上面的步骤很明显出现了问题，导致B,C同时获取了锁。在检测到锁超时后，线程不能直接简单地执行 DEL 删除键的操作以获得锁。  
对于上面的步骤进行改进，问题是出在删除键的操作上面，那么获取锁之后应该怎么改进呢？  
首先看一下redis的GETSET这个操作，GETSET key value，将给定 key 的值设为 value ，并返回 key 的旧值(old value)。利用这个操作指令，我们改进一下上述的步骤。

1. A已经首先获得了锁 lock.id，然后线A断线。B,C都在等待竞争该锁；
2. B,C读取lock.id的值，比较当前时间和键 lock.id 的值来判断是否超时，发现超时；
3. B检测到锁已超时，即当前的时间大于键 lock.id 的值，B会执行
GETSET lock.id <current Unix timestamp + lock timeout + 1>设置时间戳，通过比较键 lock.id 的旧值是否小于当前时间，判断进程是否已获得锁；
4. B发现GETSET返回的值小于当前时间，则执行 DEL lock.id命令，并执行 SETNX lock.id 命令，并返回1，B获得锁；
5. C执行GETSET得到的时间大于当前时间，则继续等待。
在线程释放锁，即执行 DEL lock.id 操作前，需要先判断锁是否已超时。如果锁已超时，那么锁可能已由其他线程获得，这时直接执行 DEL lock.id 操作会导致把其他线程已获得的锁释放掉。

**一种实现方法**

1. 获取锁

```
public boolean lock(long acquireTimeout, TimeUnit timeUnit) throws InterruptedException {
    acquireTimeout = timeUnit.toMillis(acquireTimeout);
    long acquireTime = acquireTimeout + System.currentTimeMillis();
    //使用J.U.C的ReentrantLock
    threadLock.tryLock(acquireTimeout, timeUnit);
    try {
    	//循环尝试
        while (true) {
        	//调用tryLock
            boolean hasLock = tryLock();
            if (hasLock) {
                //获取锁成功
                return true;
            } else if (acquireTime < System.currentTimeMillis()) {
                break;
            }
            Thread.sleep(sleepTime);
        }
    } finally {
        if (threadLock.isHeldByCurrentThread()) {
            threadLock.unlock();
        }
    }
    return false;
}
public boolean tryLock() {
    long currentTime = System.currentTimeMillis();
    String expires = String.valueOf(timeout + currentTime);
    //设置互斥量
    if (redisHelper.setNx(mutex, expires) > 0) {
    	//获取锁，设置超时时间
        setLockStatus(expires);
        return true;
    } else {
        String currentLockTime = redisUtil.get(mutex);
        //检查锁是否超时
        if (Objects.nonNull(currentLockTime) && Long.parseLong(currentLockTime) < currentTime) {
            //获取旧的锁时间并设置互斥量
            String oldLockTime = redisHelper.getSet(mutex, expires);
            //旧值与当前时间比较
            if (Objects.nonNull(oldLockTime) && Objects.equals(oldLockTime, currentLockTime)) {
            	//获取锁，设置超时时间
                setLockStatus(expires);
                return true;
            }
        }
        return false;
    }
}

```

lock调用tryLock方法，参数为获取的超时时间与单位，线程在超时时间内，获取锁操作将自旋在那里，直到该自旋锁的保持者释放了锁。

tryLock方法中，主要逻辑如下：

- setnx(lockkey, 当前时间+过期超时时间) ，如果返回1，则获取锁成功；如果返回0则没有获取到锁
- get(lockkey)获取值oldExpireTime ，并将这个value值与当前的系统时间进行比较，如果小于当前系统时间，则认为这个锁已经超时，可以允许别的请求重新获取
- 计算newExpireTime=当前时间+过期超时时间，然后getset(lockkey, newExpireTime) 会返回当前lockkey的值currentExpireTime
- 判断currentExpireTime与oldExpireTime 是否相等，如果相等，说明当前getset设置成功，获取到了锁。如果不相等，说明这个锁又被别的请求获取走了，那么当前请求可以直接返回失败，或者继续重试

2. 释放锁

```
public boolean unlock() {
    //只有锁的持有线程才能解锁
    if (lockHolder == Thread.currentThread()) {
        //判断锁是否超时，没有超时才将互斥量删除
        if (lockExpiresTime > System.currentTimeMillis()) {
            redisHelper.del(mutex);
            logger.info("删除互斥量[{}]", mutex);
        }
        lockHolder = null;
        logger.info("释放[{}]锁成功", mutex);
        return true;
    } else {
        throw new IllegalMonitorStateException("没有获取到锁的线程无法执行解锁操作");
    }
}
```


## 缓存系统负责接收记录用户请求，消息中间件负责将缓存中的请求同步到数据库。

## 使用ThreadLocal缓存User对象


## 动静分离：


## 流量削峰 更多的延缓用户请求的发出，以便减少和过滤掉一些无效请求

## 服务器缓存秒杀商品，直接调用缓存层，无需穿透到数据库层找数据。

# 实现二：
## 秒杀进行的过程包含两步骤： 
1. 步骤一（秒杀）：在Redis里进行秒杀。 这个步骤用户并发量非常大，抢到后，给与30分钟的时间等待用户付款， 如果用户过期未付款，则Redis库存加1 ，算用户自动放弃付款。

2. 步骤二（付款）：用户付款成功后，后台把付款记录持久化到MySQL中，这个步骤并发量相对小一点，使用数据库的事务解决数据一致性问题



## 1. 先经过Nginx负载均衡 通过配置文件配置限流功能：来在多个资源（一般是服务器）中分配负载，达到最优化资源使用，避免过载。
  - 轮询（默认）

### 限流算法
1. 计数器算法

   1. 采用计数器实现限流有点简单粗暴，一般我们会限制一秒钟的能够通过的请求数，比如限流qps为100，算法的实现思路就是从第一个请求进来开始计时，在接下去的1s内，每来一个请求，就把计数加1，如果累加的数字达到了100，那么后续的请求就会被全部拒绝。等到1s结束后，把计数恢复成0，重新开始计数。
   具体的实现可以是这样的：对于每次服务调用，可以通过AtomicLong#incrementAndGet()方法来给计数器加1并返回最新值，通过这个最新值和阈值进行比较。
   这种实现方式，相信大家都知道有一个弊端：如果我在单位时间1s内的前10ms，已经通过了100个请求，那后面的990ms，只能眼巴巴的把请求拒绝，我们把这种现象称为“突刺现象”
    
    1. 漏桶算法

   为了消除"突刺现象"，可以采用漏桶算法实现限流，漏桶算法这个名字就很形象，算法内部有一个容器，类似生活用到的漏斗，当请求进来时，相当于水倒入漏斗，然后从下端小口慢慢匀速的流出。不管上面流量多大，下面流出的速度始终保持不变。
   不管服务调用方多么不稳定，通过漏桶算法进行限流，每10毫秒处理一次请求。因为处理的速度是固定的，请求进来的速度是未知的，可能突然进来很多请求，没来得及处理的请求就先放在桶里，既然是个桶，肯定是有容量上限，如果桶满了，那么新进来的请求就丢弃。
   在算法实现方面，可以准备一个队列，用来保存请求，另外通过一个线程池（ScheduledExecutorService）来定期从队列中获取请求并执行，可以一次性获取多个并发执行。这种算法，在使用过后也存在弊端：无法应对短时间的突发流量。
    1. 令牌桶算法

   从某种意义上讲，令牌桶算法是对漏桶算法的一种改进，桶算法能够限制请求调用的速率，而令牌桶算法能够在限制调用的平均速率的同时还允许一定程度的突发调用。
   在令牌桶算法中，存在一个桶，用来存放固定数量的令牌。算法中存在一种机制，以一定的速率往桶中放令牌。每次请求调用需要先获取令牌，只有拿到令牌，才有机会继续执行，否则选择选择等待可用的令牌、或者直接拒绝。
   放令牌这个动作是持续不断的进行，如果桶中令牌数达到上限，就丢弃令牌，所以就存在这种情况，桶中一直有大量的可用令牌，这时进来的请求就可以直接拿到令牌执行，比如设置qps为100，那么限流器初始化完成一秒后，桶中就已经有100个令牌了，这时服务还没完全启动好，等启动完成对外提供服务时，该限流器可以抵挡瞬时的100个请求。所以，只有桶中没有令牌时，请求才会进行等待，最后相当于以一定的速率执行。

    ![](https://ws1.sinaimg.cn/large/007SLs93ly1g67k21f4afj30ke0mp3yh.jpg)

    实现思路：可以准备一个队列，用来保存令牌，另外通过一个线程池定期生成令牌放到队列中，每来一个请求，就从队列中获取一个令牌，并继续执行。

    1. 集群限流
      比如为了限制某个资源被每个用户或者商户的访问次数，5s只能访问2次，或者一天只能调用1000次，这种需求，单机限流是无法实现的，这时就需要通过集群限流进行实现。
   如何实现？
   为了控制访问次数，肯定需要一个计数器，而且这个计数器只能保存在第三方服务，比如redis。
   大概思路：每次有相关操作的时候，就向redis服务器发送一个incr命令，比如需要限制某个用户访问/index接口的次数，只需要拼接用户id和接口名生成redis的key，每次该用户访问此接口时，只需要对这个key执行incr命令，在这个key带上过期时间，就可以实现指定时间的访问频率。

 


## 2. Redis判断是否秒杀过。
避免重复秒杀。如果没有秒杀过 把用户名（这里是手机号）和seckillId封装成一条消息发送到RabbitMQ，请求变成被顺序串行处理 
立即返回状态“排队中”到客户端上，客户端上回显示“排队中...”

## 3. 后台监听RabbitMQ里消息，每次取一条消息，并解析后，请求Redis做库存减1操作（decr命令） 
并手动ACK队列 如果减库存成功，则在Redis里记录下库存成功的用户手机号userPhone.

## 4. 客户端排队成功后，定时请求后台查询是否秒杀成功，后面会去查询Redis是否秒杀成功
如果抢购成功，或者抢购失败则停止定时查询， 如果是排队中，则继续定时查询。
mq:user:~123456
redis:~12345
mysq:~123456


## 设计秒杀系统要考虑哪些点?
1、数据预热 秒杀都是瞬时操作，不要等流量来了再加载数据。可以提前对数据进行预热，比如加载到缓存等。
2、缓存 包括CDN缓存和数据缓存。保证缓存系统的高可用，数据随后落地。
3、解决超卖 引入MQ，串行化操作库存，达到阈值后不再消费，并关闭购买功能。或者直接操作缓存。
4、流量削峰 通过引入MQ，将耗时业务进行削峰，平稳处理用户需求。
5、熔断限流 熔断，优先保证主要业务的进行。限流，识别异常流量，进行封锁；同时，允许部分请求失败。
6、弹性扩容 在判断系统负载达到极限时，可以通过增加服务器的途径抵抗峰值。需要打通运维环境，能够快速扩容。
